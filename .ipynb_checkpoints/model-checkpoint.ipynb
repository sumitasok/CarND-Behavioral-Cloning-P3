{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import csv\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import gc; gc.collect()\n",
    "%matplotlib inline\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = base_path+ 'IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                image_resized = cv2.resize(center_image[60:140,:], (64,64))\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(image_resized)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield (X_train, y_train)\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file identifier:  1504196382763374\n"
     ]
    }
   ],
   "source": [
    "# base_path =  '/Users/sumitasok/Documents/Self-Driving Car/Behavioural Cloning/data/'\n",
    "base_path =  '/Users/sumitasok/Documents/Self-Driving Car/Behavioural Cloning/Training data/'\n",
    "import time\n",
    "import augmentation\n",
    "# base_path =  '/Users/sumitasok/Documents/Self-Driving Car/Behavioural Cloning/Training Data/'\n",
    "base_path =  '/Users/sumitasok/Documents/Self-Driving Car/Behavioural Cloning/data/'\n",
    "base_path = '/data/'\n",
    "timestamp = str(int(time.time()*1000000))\n",
    "print(\"file identifier: \", timestamp)\n",
    "results_dir = \"/src/results/model-\" + timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop(image):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/IMG/center_2017_08_04_20_07_55_755.jpg\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/home/travis/miniconda/conda-bld/conda_1486587071158/work/opencv-3.1.0/modules/imgproc/src/color.cpp:7456: error: (-215) scn == 3 || scn == 4 in function ipp_cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-87161128b790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgrady\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_sobel_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/preprocessing.py\u001b[0m in \u001b[0;36mabs_sobel_thresh\u001b[0;34m(img, orient, sobel_kernel, thresh_min, thresh_max)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mabs_sobel_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;31m# Apply cv2.Sobel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0msobelx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSobel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_64F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msobel_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/travis/miniconda/conda-bld/conda_1486587071158/work/opencv-3.1.0/modules/imgproc/src/color.cpp:7456: error: (-215) scn == 3 || scn == 4 in function ipp_cvtColor\n"
     ]
    }
   ],
   "source": [
    "import preprocessing as pro\n",
    "\n",
    "with open(training_data_base_path + 'driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    row1 = next(reader)\n",
    "    filename = row1[0].split('/')[-1]\n",
    "    current_path = base_path + 'IMG/' + filename\n",
    "    print(current_path)\n",
    "    image = mpimg.imread(current_path)\n",
    "    \n",
    "    ksize = 15\n",
    "    grady = pro.abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh_min=0, thresh_max=255)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     plot\n",
    "    f, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title(image.shape, fontsize=20)\n",
    "\n",
    "    ax2.imshow(grady)\n",
    "    ax2.set_title(grady.shape, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "training_data_base_path = base_path\n",
    "with open(training_data_base_path + 'driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "samples = []\n",
    "with open(training_data_base_path + 'driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "\n",
    "for line in train_samples:\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = base_path + 'IMG/' + filename\n",
    "    image = cv2.imread(current_path)\n",
    "    # image = cv2.resize(image[60:140,:], (64,64))\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "straight images count:  22 measurements count:  22 22\n",
      "angle images count:  0 measurements count:  0 22\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "str_imgs, str_msr, agl_imgs, agl_msr = augmentation.split_straight_angle(images, measurements)\n",
    "str_images, str_measurements = str_imgs, str_msr # augmentation.remove_excess_straigth_drive(str_imgs, str_msr, len(agl_imgs)/len(str_imgs))\n",
    "agl_images, agl_measurements = augmentation.invert_images_and_measurements(agl_imgs, agl_msr)\n",
    "\n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(measurements)\n",
    "X_train = np.array(str_images + agl_images)\n",
    "y_train = np.array(str_measurements + agl_measurements)\n",
    "\n",
    "print(\"straight images count: \", len(str_images), \"measurements count: \", len(str_measurements), len(X_train))\n",
    "print(\"angle images count: \", len(agl_images), \"measurements count: \", len(agl_measurements), len(y_train))\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "for line in validation_samples:\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = base_path + 'IMG/' + filename\n",
    "    image = cv2.imread(current_path)\n",
    "    # image = cv2.resize(image[60:140,:], (64,64))\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "\n",
    "X_val = np.array(images)\n",
    "y_val = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize generators\n",
    "train_gen = generate_training_data(image_paths_train, angles_train, validation_flag=False, batch_size=64)\n",
    "val_gen = generate_training_data(image_paths_train, angles_train, validation_flag=True, batch_size=64)\n",
    "test_gen = generate_training_data(image_paths_test, angles_test, validation_flag=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a660f7645ec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_generator' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "# from keras.layers.advanced_activations import ELU\n",
    "\n",
    "model = Sequential()\n",
    "# normaliastion of training data.\n",
    "# https://keras.io/layers/convolutional/#cropping2d\n",
    "model.add(Cropping2D(cropping=((64, 23),(0, 0)), input_shape=(160, 320, 3)))\n",
    "# model.add(Lambda(lambda x: ((x/255.0)-0.5), input_shape=(160, 320, 3)))\n",
    "model.add(Lambda(lambda x: ((x/255.0)-0.5), input_shape=(100, 180, 3)))\n",
    "model.add(Conv2D(6,5,5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(6,5,5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(4,3,3, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(127))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(84))\n",
    "# model.add(ELU)\n",
    "model.add(Dense(24))\n",
    "# model.add(ELU)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=1)\n",
    "\n",
    "# model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=1)\n",
    "model.fit_generator(data_generator, samples_per_epoch = math.ceil(len(X_train)),\n",
    "                    nb_epoch=1, validation_data = valid_generator, nb_val_samples = len(X_val))\n",
    "    history = model.fit_generator(train_gen, validation_data=val_gen, nb_val_samples=2560, samples_per_epoch=23040, \n",
    "                                  nb_epoch=5, verbose=2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "model_json = model.to_json()\n",
    "with open(results_file +\".json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "model.save(results_file +'.h5')\n",
    "model.summary()\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file=results_file + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
